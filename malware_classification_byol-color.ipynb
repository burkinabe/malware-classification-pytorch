{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2ca865c-059a-4e53-8851-0d75b2227988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mburkinabe\u001b[0m (\u001b[33mmaster-thesis-uvbf\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mburkinabe\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aed928c9ba54e31b0f5bab3ad851de6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669976916667415, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/aksavadogo/codespace/anacondaProject/malware-classification-pytorch/wandb/run-20240628_104743-hscurve_color_byol_100epochs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/burkinabe/contrastive-learning-pytorch/runs/hscurve_color_byol_100epochs' target=\"_blank\">hscurve_color_byol_100epochs</a></strong> to <a href='https://wandb.ai/burkinabe/contrastive-learning-pytorch' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/burkinabe/contrastive-learning-pytorch' target=\"_blank\">https://wandb.ai/burkinabe/contrastive-learning-pytorch</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/burkinabe/contrastive-learning-pytorch/runs/hscurve_color_byol_100epochs' target=\"_blank\">https://wandb.ai/burkinabe/contrastive-learning-pytorch/runs/hscurve_color_byol_100epochs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x77cde2090c50>> (for post_run_cell), with arguments args (<ExecutionResult object at 77cde3156d50, execution_count=3 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 77cde3155ed0, raw_cell=\"import wandb\n",
      "\n",
      "wandb.login()\n",
      "\n",
      "run = wandb.init(\n",
      "   ..\" store_history=True silent=False shell_futures=True cell_id=a2ca865c-059a-4e53-8851-0d75b2227988> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"contrastive-learning-pytorch\",\n",
    "    entity=\"burkinabe\", id=\"hscurve_color_byol_100epochs\",\n",
    "    config={\n",
    "        \"epochs\": 100\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135adee6-9f29-4b9d-8ad3-73fc45dfe198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x77cde2090c50>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 77cde210a190, raw_cell=\"# Note: The model and training settings do not fol..\" store_history=True silent=False shell_futures=True cell_id=135adee6-9f29-4b9d-8ad3-73fc45dfe198>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "epoch: 00, loss: -0.28103\n",
      "epoch: 00, train accuracy: 0.79901, val accuracy: 0.69354, F1 score: 0.69165\n",
      "epoch: 01, loss: -0.73666\n",
      "epoch: 01, train accuracy: 0.80078, val accuracy: 0.68750, F1 score: 0.68753\n",
      "epoch: 02, loss: -0.80074\n",
      "epoch: 02, train accuracy: 0.80611, val accuracy: 0.69141, F1 score: 0.68980\n",
      "epoch: 03, loss: -0.81039\n",
      "epoch: 03, train accuracy: 0.79972, val accuracy: 0.71875, F1 score: 0.71788\n",
      "epoch: 04, loss: -0.81491\n",
      "epoch: 04, train accuracy: 0.80398, val accuracy: 0.70206, F1 score: 0.70158\n",
      "epoch: 05, loss: -0.82378\n",
      "epoch: 05, train accuracy: 0.81428, val accuracy: 0.71662, F1 score: 0.71642\n",
      "epoch: 06, loss: -0.83355\n",
      "epoch: 06, train accuracy: 0.79545, val accuracy: 0.70810, F1 score: 0.70687\n",
      "epoch: 07, loss: -0.84373\n",
      "epoch: 07, train accuracy: 0.80291, val accuracy: 0.71662, F1 score: 0.71711\n",
      "epoch: 08, loss: -0.85378\n",
      "epoch: 08, train accuracy: 0.79261, val accuracy: 0.72301, F1 score: 0.72271\n",
      "epoch: 09, loss: -0.86250\n",
      "epoch: 09, train accuracy: 0.79723, val accuracy: 0.68999, F1 score: 0.68925\n",
      "epoch: 10, loss: -0.87439\n",
      "epoch: 10, train accuracy: 0.78871, val accuracy: 0.72301, F1 score: 0.72096\n",
      "epoch: 11, loss: -0.88359\n",
      "epoch: 11, train accuracy: 0.79155, val accuracy: 0.72159, F1 score: 0.72111\n",
      "epoch: 12, loss: -0.89533\n",
      "epoch: 12, train accuracy: 0.80256, val accuracy: 0.73402, F1 score: 0.73383\n",
      "epoch: 13, loss: -0.90229\n",
      "epoch: 13, train accuracy: 0.79652, val accuracy: 0.73686, F1 score: 0.73597\n",
      "epoch: 14, loss: -0.91000\n",
      "epoch: 14, train accuracy: 0.78729, val accuracy: 0.71484, F1 score: 0.71415\n",
      "epoch: 15, loss: -0.91997\n",
      "epoch: 15, train accuracy: 0.78871, val accuracy: 0.73224, F1 score: 0.73096\n",
      "epoch: 16, loss: -0.92588\n",
      "epoch: 16, train accuracy: 0.79474, val accuracy: 0.72905, F1 score: 0.72773\n",
      "epoch: 17, loss: -0.93305\n",
      "epoch: 17, train accuracy: 0.80327, val accuracy: 0.72798, F1 score: 0.72685\n",
      "epoch: 18, loss: -0.93879\n",
      "epoch: 18, train accuracy: 0.79155, val accuracy: 0.73189, F1 score: 0.73093\n",
      "epoch: 19, loss: -0.94380\n",
      "epoch: 19, train accuracy: 0.80362, val accuracy: 0.72656, F1 score: 0.72441\n",
      "epoch: 20, loss: -0.94990\n",
      "epoch: 20, train accuracy: 0.78480, val accuracy: 0.71946, F1 score: 0.71840\n",
      "epoch: 21, loss: -0.95224\n",
      "epoch: 21, train accuracy: 0.79261, val accuracy: 0.71911, F1 score: 0.71835\n",
      "epoch: 22, loss: -0.95629\n",
      "epoch: 22, train accuracy: 0.79013, val accuracy: 0.71768, F1 score: 0.71696\n",
      "epoch: 23, loss: -0.95987\n",
      "epoch: 23, train accuracy: 0.77486, val accuracy: 0.71307, F1 score: 0.71208\n",
      "epoch: 24, loss: -0.96201\n",
      "epoch: 24, train accuracy: 0.76598, val accuracy: 0.69815, F1 score: 0.69731\n",
      "epoch: 25, loss: -0.96505\n",
      "epoch: 25, train accuracy: 0.78480, val accuracy: 0.71307, F1 score: 0.71214\n",
      "epoch: 26, loss: -0.96750\n",
      "epoch: 26, train accuracy: 0.79830, val accuracy: 0.71129, F1 score: 0.70964\n",
      "epoch: 27, loss: -0.97044\n",
      "epoch: 27, train accuracy: 0.79403, val accuracy: 0.72159, F1 score: 0.72061\n",
      "epoch: 28, loss: -0.97230\n",
      "epoch: 28, train accuracy: 0.79901, val accuracy: 0.72159, F1 score: 0.71969\n",
      "epoch: 29, loss: -0.97299\n",
      "epoch: 29, train accuracy: 0.78764, val accuracy: 0.71839, F1 score: 0.71688\n",
      "epoch: 30, loss: -0.97552\n",
      "epoch: 30, train accuracy: 0.79084, val accuracy: 0.72621, F1 score: 0.72479\n",
      "epoch: 31, loss: -0.97694\n",
      "epoch: 31, train accuracy: 0.78125, val accuracy: 0.71555, F1 score: 0.71423\n",
      "epoch: 32, loss: -0.97852\n",
      "epoch: 32, train accuracy: 0.78338, val accuracy: 0.71697, F1 score: 0.71563\n",
      "epoch: 33, loss: -0.97950\n",
      "epoch: 33, train accuracy: 0.79261, val accuracy: 0.71555, F1 score: 0.71382\n",
      "epoch: 34, loss: -0.98073\n",
      "epoch: 34, train accuracy: 0.78835, val accuracy: 0.72514, F1 score: 0.72350\n",
      "epoch: 35, loss: -0.98173\n",
      "epoch: 35, train accuracy: 0.78764, val accuracy: 0.72869, F1 score: 0.72730\n",
      "epoch: 36, loss: -0.98230\n",
      "epoch: 36, train accuracy: 0.79084, val accuracy: 0.72266, F1 score: 0.72158\n",
      "epoch: 37, loss: -0.98352\n",
      "epoch: 37, train accuracy: 0.78054, val accuracy: 0.72692, F1 score: 0.72673\n",
      "epoch: 38, loss: -0.98422\n",
      "epoch: 38, train accuracy: 0.78587, val accuracy: 0.70206, F1 score: 0.70074\n",
      "epoch: 39, loss: -0.98515\n",
      "epoch: 39, train accuracy: 0.78622, val accuracy: 0.71165, F1 score: 0.70985\n",
      "epoch: 40, loss: -0.98578\n",
      "epoch: 40, train accuracy: 0.78089, val accuracy: 0.71982, F1 score: 0.71890\n",
      "epoch: 41, loss: -0.98617\n",
      "epoch: 41, train accuracy: 0.78516, val accuracy: 0.72798, F1 score: 0.72604\n",
      "epoch: 42, loss: -0.98674\n",
      "epoch: 42, train accuracy: 0.77024, val accuracy: 0.71662, F1 score: 0.71587\n",
      "epoch: 43, loss: -0.98756\n",
      "epoch: 43, train accuracy: 0.78800, val accuracy: 0.71662, F1 score: 0.71497\n",
      "epoch: 44, loss: -0.98782\n",
      "epoch: 44, train accuracy: 0.78161, val accuracy: 0.70668, F1 score: 0.70582\n",
      "epoch: 45, loss: -0.98821\n",
      "epoch: 45, train accuracy: 0.78835, val accuracy: 0.70561, F1 score: 0.70492\n",
      "epoch: 46, loss: -0.98855\n",
      "epoch: 46, train accuracy: 0.78232, val accuracy: 0.73011, F1 score: 0.72810\n",
      "epoch: 47, loss: -0.98918\n",
      "epoch: 47, train accuracy: 0.76776, val accuracy: 0.73118, F1 score: 0.73037\n",
      "epoch: 48, loss: -0.98908\n",
      "epoch: 48, train accuracy: 0.78764, val accuracy: 0.73970, F1 score: 0.73894\n",
      "epoch: 49, loss: -0.98978\n",
      "epoch: 49, train accuracy: 0.77592, val accuracy: 0.72088, F1 score: 0.71911\n",
      "epoch: 50, loss: -0.98983\n",
      "epoch: 50, train accuracy: 0.77450, val accuracy: 0.72834, F1 score: 0.72658\n",
      "epoch: 51, loss: -0.99017\n",
      "epoch: 51, train accuracy: 0.77628, val accuracy: 0.72195, F1 score: 0.71944\n",
      "epoch: 52, loss: -0.99049\n",
      "epoch: 52, train accuracy: 0.77841, val accuracy: 0.72479, F1 score: 0.72423\n",
      "epoch: 53, loss: -0.99085\n",
      "epoch: 53, train accuracy: 0.77592, val accuracy: 0.72940, F1 score: 0.72843\n",
      "epoch: 54, loss: -0.99116\n",
      "epoch: 54, train accuracy: 0.77628, val accuracy: 0.72443, F1 score: 0.72283\n",
      "epoch: 55, loss: -0.99106\n",
      "epoch: 55, train accuracy: 0.77344, val accuracy: 0.72727, F1 score: 0.72496\n",
      "epoch: 56, loss: -0.99148\n",
      "epoch: 56, train accuracy: 0.78018, val accuracy: 0.73509, F1 score: 0.73382\n",
      "epoch: 57, loss: -0.99163\n",
      "epoch: 57, train accuracy: 0.77876, val accuracy: 0.72408, F1 score: 0.72208\n",
      "epoch: 58, loss: -0.99180\n",
      "epoch: 58, train accuracy: 0.78161, val accuracy: 0.72514, F1 score: 0.72355\n",
      "epoch: 59, loss: -0.99185\n",
      "epoch: 59, train accuracy: 0.76705, val accuracy: 0.72230, F1 score: 0.72122\n",
      "epoch: 60, loss: -0.99210\n",
      "epoch: 60, train accuracy: 0.77379, val accuracy: 0.73224, F1 score: 0.73133\n",
      "epoch: 61, loss: -0.99228\n",
      "epoch: 61, train accuracy: 0.78232, val accuracy: 0.69744, F1 score: 0.69628\n",
      "epoch: 62, loss: -0.99252\n",
      "epoch: 62, train accuracy: 0.77095, val accuracy: 0.71307, F1 score: 0.71121\n",
      "epoch: 63, loss: -0.99262\n",
      "epoch: 63, train accuracy: 0.78587, val accuracy: 0.72550, F1 score: 0.72379\n",
      "epoch: 64, loss: -0.99279\n",
      "epoch: 64, train accuracy: 0.77344, val accuracy: 0.72195, F1 score: 0.72039\n",
      "epoch: 65, loss: -0.99261\n",
      "epoch: 65, train accuracy: 0.77344, val accuracy: 0.73615, F1 score: 0.73451\n",
      "epoch: 66, loss: -0.99278\n",
      "epoch: 66, train accuracy: 0.77841, val accuracy: 0.73615, F1 score: 0.73427\n",
      "epoch: 67, loss: -0.99282\n",
      "epoch: 67, train accuracy: 0.77237, val accuracy: 0.72514, F1 score: 0.72380\n",
      "epoch: 68, loss: -0.99290\n",
      "epoch: 68, train accuracy: 0.77805, val accuracy: 0.73224, F1 score: 0.73103\n",
      "epoch: 69, loss: -0.99320\n",
      "epoch: 69, train accuracy: 0.77166, val accuracy: 0.73224, F1 score: 0.73155\n",
      "epoch: 70, loss: -0.99315\n",
      "epoch: 70, train accuracy: 0.78409, val accuracy: 0.70632, F1 score: 0.70547\n",
      "epoch: 71, loss: -0.99319\n",
      "epoch: 71, train accuracy: 0.77060, val accuracy: 0.71946, F1 score: 0.71715\n",
      "epoch: 72, loss: -0.99333\n",
      "epoch: 72, train accuracy: 0.78054, val accuracy: 0.73189, F1 score: 0.73042\n",
      "epoch: 73, loss: -0.99332\n",
      "epoch: 73, train accuracy: 0.76562, val accuracy: 0.72798, F1 score: 0.72693\n",
      "epoch: 74, loss: -0.99345\n",
      "epoch: 74, train accuracy: 0.77876, val accuracy: 0.70348, F1 score: 0.70322\n",
      "epoch: 75, loss: -0.99352\n",
      "epoch: 75, train accuracy: 0.76314, val accuracy: 0.71911, F1 score: 0.71772\n",
      "epoch: 76, loss: -0.99347\n",
      "epoch: 76, train accuracy: 0.77699, val accuracy: 0.72266, F1 score: 0.72065\n",
      "epoch: 77, loss: -0.99351\n",
      "epoch: 77, train accuracy: 0.78054, val accuracy: 0.72266, F1 score: 0.72118\n",
      "epoch: 78, loss: -0.99385\n",
      "epoch: 78, train accuracy: 0.76420, val accuracy: 0.72159, F1 score: 0.71829\n",
      "epoch: 79, loss: -0.99355\n",
      "epoch: 79, train accuracy: 0.78906, val accuracy: 0.72727, F1 score: 0.72682\n",
      "epoch: 80, loss: -0.99379\n",
      "epoch: 80, train accuracy: 0.77344, val accuracy: 0.70916, F1 score: 0.70757\n",
      "epoch: 81, loss: -0.99368\n",
      "epoch: 81, train accuracy: 0.77379, val accuracy: 0.73011, F1 score: 0.72751\n",
      "epoch: 82, loss: -0.99379\n",
      "epoch: 82, train accuracy: 0.77521, val accuracy: 0.72053, F1 score: 0.71898\n",
      "epoch: 83, loss: -0.99381\n",
      "epoch: 83, train accuracy: 0.77521, val accuracy: 0.72088, F1 score: 0.71919\n",
      "epoch: 84, loss: -0.99393\n",
      "epoch: 84, train accuracy: 0.77841, val accuracy: 0.72869, F1 score: 0.72712\n",
      "epoch: 85, loss: -0.99391\n",
      "epoch: 85, train accuracy: 0.77379, val accuracy: 0.73118, F1 score: 0.72996\n",
      "epoch: 86, loss: -0.99383\n",
      "epoch: 86, train accuracy: 0.76847, val accuracy: 0.71200, F1 score: 0.70899\n",
      "epoch: 87, loss: -0.99369\n",
      "epoch: 87, train accuracy: 0.77024, val accuracy: 0.73366, F1 score: 0.73206\n",
      "epoch: 88, loss: -0.99387\n",
      "epoch: 88, train accuracy: 0.76030, val accuracy: 0.72479, F1 score: 0.72298\n",
      "epoch: 89, loss: -0.99384\n",
      "epoch: 89, train accuracy: 0.77876, val accuracy: 0.72692, F1 score: 0.72515\n",
      "epoch: 90, loss: -0.99365\n",
      "epoch: 90, train accuracy: 0.77308, val accuracy: 0.72372, F1 score: 0.72192\n",
      "epoch: 91, loss: -0.99375\n",
      "epoch: 91, train accuracy: 0.78445, val accuracy: 0.71911, F1 score: 0.71784\n",
      "epoch: 92, loss: -0.99385\n",
      "epoch: 92, train accuracy: 0.76882, val accuracy: 0.71626, F1 score: 0.71473\n",
      "epoch: 93, loss: -0.99395\n",
      "epoch: 93, train accuracy: 0.76811, val accuracy: 0.70490, F1 score: 0.70247\n",
      "epoch: 94, loss: -0.99406\n",
      "epoch: 94, train accuracy: 0.77876, val accuracy: 0.72337, F1 score: 0.72049\n",
      "epoch: 95, loss: -0.99400\n",
      "epoch: 95, train accuracy: 0.77415, val accuracy: 0.71591, F1 score: 0.71415\n",
      "epoch: 96, loss: -0.99388\n",
      "epoch: 96, train accuracy: 0.77202, val accuracy: 0.70561, F1 score: 0.70373\n",
      "epoch: 97, loss: -0.99390\n",
      "epoch: 97, train accuracy: 0.78480, val accuracy: 0.71911, F1 score: 0.71886\n",
      "epoch: 98, loss: -0.99404\n",
      "epoch: 98, train accuracy: 0.77060, val accuracy: 0.71023, F1 score: 0.70994\n",
      "epoch: 99, loss: -0.99403\n",
      "epoch: 99, train accuracy: 0.77770, val accuracy: 0.71236, F1 score: 0.71189\n",
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x77cde2090c50>> (for post_run_cell), with arguments args (<ExecutionResult object at 77cde31677d0, execution_count=5 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 77cde210a190, raw_cell=\"# Note: The model and training settings do not fol..\" store_history=True silent=False shell_futures=True cell_id=135adee6-9f29-4b9d-8ad3-73fc45dfe198> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "# Note: The model and training settings do not follow the reference settings\n",
    "# from the paper. The settings are chosen such that the example can easily be\n",
    "# run on a small dataset with a single GPU.\n",
    "\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules import BYOLPredictionHead, BYOLProjectionHead\n",
    "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "from lightly.transforms.byol_transform import (\n",
    "    BYOLTransform,\n",
    "    BYOLView1Transform,\n",
    "    BYOLView2Transform,\n",
    ")\n",
    "from lightly.utils.scheduler import cosine_schedule\n",
    "from lightly.data.dataset import LightlyDataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from lightly.transforms import utils\n",
    "\n",
    "\n",
    "class BYOL(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super().__init__()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = BYOLProjectionHead(512, 1024, 256)\n",
    "        self.prediction_head = BYOLPredictionHead(256, 1024, 256)\n",
    "\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "\n",
    "        deactivate_requires_grad(self.backbone_momentum)\n",
    "        deactivate_requires_grad(self.projection_head_momentum)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(y)\n",
    "        p = self.prediction_head(z)\n",
    "        return p\n",
    "\n",
    "    def forward_momentum(self, x):\n",
    "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
    "        z = self.projection_head_momentum(y)\n",
    "        z = z.detach()\n",
    "        return z\n",
    "\n",
    "\n",
    "resnet = torchvision.models.resnet18()\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "model = BYOL(backbone)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# We disable resizing and gaussian blur for cifar10.\n",
    "transform = BYOLTransform(\n",
    "    view_1_transform=BYOLView1Transform(input_size=32, gaussian_blur=0.0),\n",
    "    view_2_transform=BYOLView2Transform(input_size=32, gaussian_blur=0.0),\n",
    ")\n",
    "#dataset = torchvision.datasets.CIFAR10(\n",
    "#    \"datasets/cifar10\", download=True, transform=transform\n",
    "#)\n",
    "\n",
    "train_dataset = ImageFolder(root='hscurvecolor/train', transform=transform)\n",
    "val_dataset = ImageFolder(root='hscurvecolor/val', transform=transform)\n",
    "\n",
    "# or create a dataset from a folder containing images or videos:\n",
    "#train_dataset = LightlyDataset(\"hscurvedataset/train\", transform=transform)\n",
    "#val_dataset = LightlyDataset(\"hscurvedataset/val\", transform=transform)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "criterion = NegativeCosineSimilarity()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.06)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    momentum_val = cosine_schedule(epoch, epochs, 0.996, 1)\n",
    "    for batch in train_dataloader:\n",
    "        x0, x1 = batch[0]\n",
    "        update_momentum(model.backbone, model.backbone_momentum, m=momentum_val)\n",
    "        update_momentum(\n",
    "            model.projection_head, model.projection_head_momentum, m=momentum_val\n",
    "        )\n",
    "        x0 = x0.to(device)\n",
    "        x1 = x1.to(device)\n",
    "        p0 = model(x0)\n",
    "        z0 = model.forward_momentum(x0)\n",
    "        p1 = model(x1)\n",
    "        z1 = model.forward_momentum(x1)\n",
    "        loss = 0.5 * (criterion(p0, z1) + criterion(p1, z0))\n",
    "        total_loss += loss.detach()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"epoch: {epoch:>02}, loss: {avg_loss:.5f}\")\n",
    "\n",
    "    # Feature extraction\n",
    "    model.eval()\n",
    "    train_features, train_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for (x0, x1), labels in train_dataloader:\n",
    "            x0 = x0.to(device)\n",
    "            features = model.backbone(x0).flatten(start_dim=1)\n",
    "            train_features.append(features.cpu())\n",
    "            train_labels.append(labels)\n",
    "\n",
    "    train_features = torch.cat(train_features).numpy()\n",
    "    train_labels = torch.cat(train_labels).numpy()\n",
    "\n",
    "    # Train a classifier on extracted features\n",
    "    classifier = LogisticRegression(max_iter=1000)\n",
    "    classifier.fit(train_features, train_labels)\n",
    "\n",
    "    # Evaluate on training data\n",
    "    train_predictions = classifier.predict(train_features)\n",
    "    train_accuracy = accuracy_score(train_labels, train_predictions)\n",
    "\n",
    "    # Validation\n",
    "    val_features, val_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for (x0, x1), labels in val_dataloader:\n",
    "            x0 = x0.to(device)\n",
    "            features = model.backbone(x0).flatten(start_dim=1)\n",
    "            val_features.append(features.cpu())\n",
    "            val_labels.append(labels)\n",
    "\n",
    "    val_features = torch.cat(val_features).numpy()\n",
    "    val_labels = torch.cat(val_labels).numpy()\n",
    "\n",
    "    # Predictions and metrics\n",
    "    val_predictions = classifier.predict(val_features)\n",
    "    val_accuracy = accuracy_score(val_labels, val_predictions)\n",
    "    f1 = f1_score(val_labels, val_predictions, average='weighted')\n",
    "\n",
    "    print(f\"epoch: {epoch:>02}, train accuracy: {train_accuracy:.5f}, val accuracy: {val_accuracy:.5f}, F1 score: {f1:.5f}\")\n",
    "    wandb.log({\"epoch\":epoch, \"train_accuracy\": train_accuracy,  \"val_accuracy\": val_accuracy, \"F1_score\":f1, \"loss\": loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6106126-8f2c-4de1-b3de-30d802463c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
