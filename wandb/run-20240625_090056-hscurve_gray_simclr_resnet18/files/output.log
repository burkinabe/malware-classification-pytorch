Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for post_run_cell), with arguments args (<ExecutionResult object at 761c98947cd0, execution_count=13 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 761be6bd6390, raw_cell="import wandb
wandb.login()
run = wandb.init(
   .." store_history=True silent=False shell_futures=True cell_id=a78334a4-6b77-4df9-8eee-62053fe38f07> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 761be7599090, raw_cell="_jupyterlab_variableinspector_dict_list()" store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for post_run_cell), with arguments args (<ExecutionResult object at 761c9947bdd0, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 761be7599090, raw_cell="_jupyterlab_variableinspector_dict_list()" store_history=False silent=False shell_futures=True cell_id=None> result='[{"varName": "avg_loss", "varType": "float", "varSize": "24", "varShape": "", "varContent": "5.596440309948392", "isMatrix": false, "isWidget": false}, {"varName": "backbone", "varType": "Sequential", "varSize": "56", "varShape": "", "varContent": "Sequential(\\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine ...", "isMatrix": false, "isWidget": false}, {"varName": "batch", "varType": "list", "varSize": "120", "varShape": "2", "varContent": "[[tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -1.4500, -1.7754, -1.1247],\\n          [-2.1179, -2.1179, -2.1179,  ..., -1.6727, -2.0494, -1.5528],\\n     ...", "isMatrix": true, "isWidget": false}, {"varName": "classifier", "varType": "LogisticRegression", "varSize": "56", "varShape": "", "varContent": "LogisticRegression(max_iter=1000)", "isMatrix": false, "isWidget": false}, {"varName": "criterion", "varType": "NTXentLoss", "varSize": "56", "varShape": "", "varContent": "NTXentLoss(\\n  (cross_entropy): CrossEntropyLoss()\\n)", "isMatrix": false, "isWidget": false}, {"varName": "device", "varType": "str", "varSize": "53", "varShape": "", "varContent": "cuda", "isMatrix": false, "isWidget": false}, {"varName": "epoch", "varType": "int", "varSize": "28", "varShape": "", "varContent": "1", "isMatrix": false, "isWidget": false}, {"varName": "f1", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.7151179756429267", "isMatrix": false, "isWidget": false}, {"varName": "features", "varType": "Tensor", "varSize": "524288", "varShape": "256 x 512", "varContent": "tensor([[0.0000, 1.2989, 0.0000,  ..., 0.0721, 0.0500, 1.0627],\\n        [0.5403, 1.4964, 0.0000,  ..., 1.5256, 0.0000, 1.5957],\\n        [0.0000, 0.821 ...", "isMatrix": true, "isWidget": false}, {"varName": "labels", "varType": "Tensor", "varSize": "2048", "varShape": "256", "varContent": "tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\\n        0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, ...", "isMatrix": true, "isWidget": false}, {"varName": "loss", "varType": "Tensor", "varSize": "4", "varShape": "", "varContent": "tensor(5.5273, device=\'cuda:0\', grad_fn=<NllLossBackward0>)", "isMatrix": true, "isWidget": false}, {"varName": "model", "varType": "SimCLR", "varSize": "56", "varShape": "", "varContent": "SimCLR(\\n  (backbone): Sequential(\\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n    (1): BatchNorm2d(64, eps=1 ...", "isMatrix": false, "isWidget": false}, {"varName": "optimizer", "varType": "SGD", "varSize": "56", "varShape": "", "varContent": "SGD (\\nParameter Group 0\\n    dampening: 0\\n    differentiable: False\\n    foreach: None\\n    fused: None\\n    lr: 0.06\\n    maximize: False\\n    momentum: 0\\n ...", "isMatrix": false, "isWidget": false}, {"varName": "resnet", "varType": "ResNet", "varSize": "56", "varShape": "", "varContent": "ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affi ...", "isMatrix": false, "isWidget": false}, {"varName": "total_loss", "varType": "float", "varSize": "24", "varShape": "", "varContent": "503.6796278953552", "isMatrix": false, "isWidget": false}, {"varName": "train_accuracy", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.780078125", "isMatrix": false, "isWidget": false}, {"varName": "train_dataset", "varType": "ImageFolder", "varSize": "56", "varShape": "", "varContent": "Dataset ImageFolder\\n    Number of datapoints: 23137\\n    Root location: hscurvedataset/train\\n    StandardTransform\\nTransform: <lightly.transforms.simcl ...", "isMatrix": false, "isWidget": false}, {"varName": "train_features", "varType": "list", "varSize": "312", "varShape": "26", "varContent": "[tensor([[2.6448, 1.7100, 2.2976,  ..., 0.0000, 0.0000, 0.0804],\\n        [0.0000, 0.0000, 0.8383,  ..., 2.1124, 1.7524, 2.0640],\\n        [0.0000, 1.90 ...", "isMatrix": true, "isWidget": false}, {"varName": "train_labels", "varType": "list", "varSize": "312", "varShape": "26", "varContent": "[tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\\n        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0 ...", "isMatrix": true, "isWidget": false}, {"varName": "train_predictions", "varType": "ndarray", "varSize": "184320", "varShape": "23040", "varContent": "array([1, 0, 0, ..., 0, 1, 0])", "isMatrix": true, "isWidget": false}, {"varName": "val_accuracy", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.7177734375", "isMatrix": false, "isWidget": false}, {"varName": "val_dataset", "varType": "ImageFolder", "varSize": "56", "varShape": "", "varContent": "Dataset ImageFolder\\n    Number of datapoints: 1160\\n    Root location: hscurvedataset/val\\n    StandardTransform\\nTransform: <lightly.transforms.simclr_t ...", "isMatrix": false, "isWidget": false}, {"varName": "val_features", "varType": "ndarray", "varSize": "2097152", "varShape": "1024 x 512", "varContent": "array([[0.        , 0.        , 0.        , ..., 3.9465685 , 0.6919681 ,\\n        1.9307051 ],\\n       [0.        , 2.0333738 , 0.04029834, ..., 0.51629 ...", "isMatrix": true, "isWidget": false}, {"varName": "val_labels", "varType": "ndarray", "varSize": "8192", "varShape": "1024", "varContent": "array([0, 0, 0, ..., 1, 1, 1])", "isMatrix": true, "isWidget": false}, {"varName": "val_predictions", "varType": "ndarray", "varSize": "8192", "varShape": "1024", "varContent": "array([1, 0, 0, ..., 1, 1, 0])", "isMatrix": true, "isWidget": false}, {"varName": "x0", "varType": "Tensor", "varSize": "3145728", "varShape": "256 x 3 x 32 x 32", "varContent": "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -1.7069, -1.7754, -1.7754],\\n          [-2.1179, -2.1179, -2.1179,  ..., -1.8439, -1.8097, -1.7754],\\n       ...", "isMatrix": false, "isWidget": false}, {"varName": "x1", "varType": "Tensor", "varSize": "3145728", "varShape": "256 x 3 x 32 x 32", "varContent": "tensor([[[[-1.3302, -1.3302, -1.3473,  ..., -2.0152, -2.0152, -2.0152],\\n          [-1.4158, -1.3815, -1.4329,  ..., -2.0152, -2.0152, -2.0152],\\n       ...", "isMatrix": false, "isWidget": false}, {"varName": "z0", "varType": "Tensor", "varSize": "131072", "varShape": "256 x 128", "varContent": "tensor([[-0.0408, -0.7401, -0.7230,  ..., -0.8900,  0.7304, -0.3235],\\n        [-1.1906,  0.2128, -0.4169,  ..., -1.3919, -0.6853, -0.2433],\\n        [  ...", "isMatrix": true, "isWidget": false}, {"varName": "z1", "varType": "Tensor", "varSize": "131072", "varShape": "256 x 128", "varContent": "tensor([[-0.1837, -0.6964, -0.6712,  ..., -1.1343,  0.5922,  0.4160],\\n        [-0.4002,  0.6432,  0.6608,  ..., -0.8682, -1.4558,  0.2638],\\n        [  ...", "isMatrix": true, "isWidget": false}]'>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 761c23f8af90, raw_cell="
import json
import getpass
import hashlib
def im.." store_history=True silent=False shell_futures=True cell_id=None>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for post_run_cell), with arguments args (<ExecutionResult object at 761be61b3c10, execution_count=14 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 761c23f8af90, raw_cell="
import json
import getpass
import hashlib
def im.." store_history=True silent=False shell_futures=True cell_id=None> result='{"dataframes": [], "user": "aksavadogo"}'>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 761be7f94bd0, raw_cell="_jupyterlab_variableinspector_dict_list()" store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for post_run_cell), with arguments args (<ExecutionResult object at 761be6147950, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 761be7f94bd0, raw_cell="_jupyterlab_variableinspector_dict_list()" store_history=False silent=False shell_futures=True cell_id=None> result='[{"varName": "avg_loss", "varType": "float", "varSize": "24", "varShape": "", "varContent": "5.596440309948392", "isMatrix": false, "isWidget": false}, {"varName": "backbone", "varType": "Sequential", "varSize": "56", "varShape": "", "varContent": "Sequential(\\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine ...", "isMatrix": false, "isWidget": false}, {"varName": "batch", "varType": "list", "varSize": "120", "varShape": "2", "varContent": "[[tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -1.4500, -1.7754, -1.1247],\\n          [-2.1179, -2.1179, -2.1179,  ..., -1.6727, -2.0494, -1.5528],\\n     ...", "isMatrix": true, "isWidget": false}, {"varName": "classifier", "varType": "LogisticRegression", "varSize": "56", "varShape": "", "varContent": "LogisticRegression(max_iter=1000)", "isMatrix": false, "isWidget": false}, {"varName": "criterion", "varType": "NTXentLoss", "varSize": "56", "varShape": "", "varContent": "NTXentLoss(\\n  (cross_entropy): CrossEntropyLoss()\\n)", "isMatrix": false, "isWidget": false}, {"varName": "device", "varType": "str", "varSize": "53", "varShape": "", "varContent": "cuda", "isMatrix": false, "isWidget": false}, {"varName": "epoch", "varType": "int", "varSize": "28", "varShape": "", "varContent": "1", "isMatrix": false, "isWidget": false}, {"varName": "f1", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.7151179756429267", "isMatrix": false, "isWidget": false}, {"varName": "features", "varType": "Tensor", "varSize": "524288", "varShape": "256 x 512", "varContent": "tensor([[0.0000, 1.2989, 0.0000,  ..., 0.0721, 0.0500, 1.0627],\\n        [0.5403, 1.4964, 0.0000,  ..., 1.5256, 0.0000, 1.5957],\\n        [0.0000, 0.821 ...", "isMatrix": true, "isWidget": false}, {"varName": "labels", "varType": "Tensor", "varSize": "2048", "varShape": "256", "varContent": "tensor([0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\\n        0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, ...", "isMatrix": true, "isWidget": false}, {"varName": "loss", "varType": "Tensor", "varSize": "4", "varShape": "", "varContent": "tensor(5.5273, device=\'cuda:0\', grad_fn=<NllLossBackward0>)", "isMatrix": true, "isWidget": false}, {"varName": "model", "varType": "SimCLR", "varSize": "56", "varShape": "", "varContent": "SimCLR(\\n  (backbone): Sequential(\\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n    (1): BatchNorm2d(64, eps=1 ...", "isMatrix": false, "isWidget": false}, {"varName": "optimizer", "varType": "SGD", "varSize": "56", "varShape": "", "varContent": "SGD (\\nParameter Group 0\\n    dampening: 0\\n    differentiable: False\\n    foreach: None\\n    fused: None\\n    lr: 0.06\\n    maximize: False\\n    momentum: 0\\n ...", "isMatrix": false, "isWidget": false}, {"varName": "resnet", "varType": "ResNet", "varSize": "56", "varShape": "", "varContent": "ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affi ...", "isMatrix": false, "isWidget": false}, {"varName": "total_loss", "varType": "float", "varSize": "24", "varShape": "", "varContent": "503.6796278953552", "isMatrix": false, "isWidget": false}, {"varName": "train_accuracy", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.780078125", "isMatrix": false, "isWidget": false}, {"varName": "train_dataset", "varType": "ImageFolder", "varSize": "56", "varShape": "", "varContent": "Dataset ImageFolder\\n    Number of datapoints: 23137\\n    Root location: hscurvedataset/train\\n    StandardTransform\\nTransform: <lightly.transforms.simcl ...", "isMatrix": false, "isWidget": false}, {"varName": "train_features", "varType": "list", "varSize": "312", "varShape": "26", "varContent": "[tensor([[2.6448, 1.7100, 2.2976,  ..., 0.0000, 0.0000, 0.0804],\\n        [0.0000, 0.0000, 0.8383,  ..., 2.1124, 1.7524, 2.0640],\\n        [0.0000, 1.90 ...", "isMatrix": true, "isWidget": false}, {"varName": "train_labels", "varType": "list", "varSize": "312", "varShape": "26", "varContent": "[tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\\n        0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0 ...", "isMatrix": true, "isWidget": false}, {"varName": "train_predictions", "varType": "ndarray", "varSize": "184320", "varShape": "23040", "varContent": "array([1, 0, 0, ..., 0, 1, 0])", "isMatrix": true, "isWidget": false}, {"varName": "val_accuracy", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.7177734375", "isMatrix": false, "isWidget": false}, {"varName": "val_dataset", "varType": "ImageFolder", "varSize": "56", "varShape": "", "varContent": "Dataset ImageFolder\\n    Number of datapoints: 1160\\n    Root location: hscurvedataset/val\\n    StandardTransform\\nTransform: <lightly.transforms.simclr_t ...", "isMatrix": false, "isWidget": false}, {"varName": "val_features", "varType": "ndarray", "varSize": "2097152", "varShape": "1024 x 512", "varContent": "array([[0.        , 0.        , 0.        , ..., 3.9465685 , 0.6919681 ,\\n        1.9307051 ],\\n       [0.        , 2.0333738 , 0.04029834, ..., 0.51629 ...", "isMatrix": true, "isWidget": false}, {"varName": "val_labels", "varType": "ndarray", "varSize": "8192", "varShape": "1024", "varContent": "array([0, 0, 0, ..., 1, 1, 1])", "isMatrix": true, "isWidget": false}, {"varName": "val_predictions", "varType": "ndarray", "varSize": "8192", "varShape": "1024", "varContent": "array([1, 0, 0, ..., 1, 1, 0])", "isMatrix": true, "isWidget": false}, {"varName": "x0", "varType": "Tensor", "varSize": "3145728", "varShape": "256 x 3 x 32 x 32", "varContent": "tensor([[[[-2.1179, -2.1179, -2.1179,  ..., -1.7069, -1.7754, -1.7754],\\n          [-2.1179, -2.1179, -2.1179,  ..., -1.8439, -1.8097, -1.7754],\\n       ...", "isMatrix": false, "isWidget": false}, {"varName": "x1", "varType": "Tensor", "varSize": "3145728", "varShape": "256 x 3 x 32 x 32", "varContent": "tensor([[[[-1.3302, -1.3302, -1.3473,  ..., -2.0152, -2.0152, -2.0152],\\n          [-1.4158, -1.3815, -1.4329,  ..., -2.0152, -2.0152, -2.0152],\\n       ...", "isMatrix": false, "isWidget": false}, {"varName": "z0", "varType": "Tensor", "varSize": "131072", "varShape": "256 x 128", "varContent": "tensor([[-0.0408, -0.7401, -0.7230,  ..., -0.8900,  0.7304, -0.3235],\\n        [-1.1906,  0.2128, -0.4169,  ..., -1.3919, -0.6853, -0.2433],\\n        [  ...", "isMatrix": true, "isWidget": false}, {"varName": "z1", "varType": "Tensor", "varSize": "131072", "varShape": "256 x 128", "varContent": "tensor([[-0.1837, -0.6964, -0.6712,  ..., -1.1343,  0.5922,  0.4160],\\n        [-0.4002,  0.6432,  0.6608,  ..., -0.8682, -1.4558,  0.2638],\\n        [  ...", "isMatrix": true, "isWidget": false}]'>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 761c20009990, raw_cell="# Note: The model and training settings do not fol.." store_history=True silent=False shell_futures=True cell_id=43b47201-d118-42aa-b4e4-410fd43a23e4>,),kwargs {}:
Starting Training
epoch: 00, loss: 5.84961
epoch: 00, train accuracy: 0.78971, val accuracy: 0.70996, F1 score: 0.70826
epoch: 01, loss: 5.56246
epoch: 01, train accuracy: 0.81619, val accuracy: 0.74414, F1 score: 0.74279
epoch: 02, loss: 5.47192
epoch: 02, train accuracy: 0.81910, val accuracy: 0.74902, F1 score: 0.74847
epoch: 03, loss: 5.41031
epoch: 03, train accuracy: 0.84848, val accuracy: 0.78223, F1 score: 0.78247
epoch: 04, loss: 5.36630
epoch: 04, train accuracy: 0.85503, val accuracy: 0.79102, F1 score: 0.79065
epoch: 05, loss: 5.33642
epoch: 05, train accuracy: 0.84931, val accuracy: 0.79395, F1 score: 0.79397
epoch: 06, loss: 5.31004
epoch: 06, train accuracy: 0.86328, val accuracy: 0.81445, F1 score: 0.81502
epoch: 07, loss: 5.28546
epoch: 07, train accuracy: 0.86914, val accuracy: 0.83105, F1 score: 0.83132
epoch: 08, loss: 5.25670
epoch: 08, train accuracy: 0.86584, val accuracy: 0.82617, F1 score: 0.82603
epoch: 09, loss: 5.24272
epoch: 09, train accuracy: 0.86571, val accuracy: 0.81543, F1 score: 0.81563
epoch: 10, loss: 5.23597
epoch: 10, train accuracy: 0.86141, val accuracy: 0.79004, F1 score: 0.78944
epoch: 11, loss: 5.22534
epoch: 11, train accuracy: 0.86892, val accuracy: 0.81934, F1 score: 0.81949
epoch: 12, loss: 5.21485
epoch: 12, train accuracy: 0.86324, val accuracy: 0.81348, F1 score: 0.81368
epoch: 13, loss: 5.20771
epoch: 13, train accuracy: 0.87344, val accuracy: 0.82324, F1 score: 0.82322
epoch: 14, loss: 5.19767
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 14, train accuracy: 0.86298, val accuracy: 0.80469, F1 score: 0.80458
epoch: 15, loss: 5.18890
epoch: 15, train accuracy: 0.86541, val accuracy: 0.80957, F1 score: 0.80915
epoch: 16, loss: 5.18813
epoch: 16, train accuracy: 0.87231, val accuracy: 0.80176, F1 score: 0.80206
epoch: 17, loss: 5.17103
epoch: 17, train accuracy: 0.87422, val accuracy: 0.82520, F1 score: 0.82543
epoch: 18, loss: 5.16577
epoch: 18, train accuracy: 0.87635, val accuracy: 0.83887, F1 score: 0.83912
epoch: 19, loss: 5.16210
epoch: 19, train accuracy: 0.87522, val accuracy: 0.82520, F1 score: 0.82566
epoch: 20, loss: 5.14555
epoch: 20, train accuracy: 0.87708, val accuracy: 0.82227, F1 score: 0.82248
epoch: 21, loss: 5.13655
epoch: 21, train accuracy: 0.88186, val accuracy: 0.81738, F1 score: 0.81770
epoch: 22, loss: 5.14115
epoch: 22, train accuracy: 0.87934, val accuracy: 0.83008, F1 score: 0.83046
epoch: 23, loss: 5.13591
epoch: 23, train accuracy: 0.88320, val accuracy: 0.82715, F1 score: 0.82738
epoch: 24, loss: 5.12641
epoch: 24, train accuracy: 0.88845, val accuracy: 0.83887, F1 score: 0.83912
epoch: 25, loss: 5.12596
epoch: 25, train accuracy: 0.88594, val accuracy: 0.84863, F1 score: 0.84896
epoch: 26, loss: 5.11361
epoch: 26, train accuracy: 0.88281, val accuracy: 0.84180, F1 score: 0.84199
epoch: 27, loss: 5.11090
epoch: 27, train accuracy: 0.88602, val accuracy: 0.83496, F1 score: 0.83498
epoch: 28, loss: 5.10950
epoch: 28, train accuracy: 0.88746, val accuracy: 0.83691, F1 score: 0.83729
epoch: 29, loss: 5.10899
epoch: 29, train accuracy: 0.88385, val accuracy: 0.82617, F1 score: 0.82617
epoch: 30, loss: 5.10113
epoch: 30, train accuracy: 0.88390, val accuracy: 0.84082, F1 score: 0.84116
epoch: 31, loss: 5.08681
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 31, train accuracy: 0.88581, val accuracy: 0.84766, F1 score: 0.84794
epoch: 32, loss: 5.09820
epoch: 32, train accuracy: 0.88281, val accuracy: 0.84375, F1 score: 0.84371
epoch: 33, loss: 5.08270
epoch: 33, train accuracy: 0.88707, val accuracy: 0.85059, F1 score: 0.85061
epoch: 34, loss: 5.07890
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 34, train accuracy: 0.88342, val accuracy: 0.84570, F1 score: 0.84582
epoch: 35, loss: 5.08256
epoch: 35, train accuracy: 0.89184, val accuracy: 0.84375, F1 score: 0.84427
epoch: 36, loss: 5.07487
epoch: 36, train accuracy: 0.88056, val accuracy: 0.81543, F1 score: 0.81583
epoch: 37, loss: 5.07575
epoch: 37, train accuracy: 0.89258, val accuracy: 0.84375, F1 score: 0.84394
epoch: 38, loss: 5.07274
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 38, train accuracy: 0.89084, val accuracy: 0.83301, F1 score: 0.83343
epoch: 39, loss: 5.05936
epoch: 39, train accuracy: 0.89015, val accuracy: 0.84961, F1 score: 0.84986
epoch: 40, loss: 5.05553
epoch: 40, train accuracy: 0.89510, val accuracy: 0.83789, F1 score: 0.83839
epoch: 41, loss: 5.07002
epoch: 41, train accuracy: 0.88668, val accuracy: 0.83691, F1 score: 0.83723
epoch: 42, loss: 5.05667
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 42, train accuracy: 0.88216, val accuracy: 0.84180, F1 score: 0.84215
epoch: 43, loss: 5.05096
epoch: 43, train accuracy: 0.89210, val accuracy: 0.84375, F1 score: 0.84423
epoch: 44, loss: 5.05284
epoch: 44, train accuracy: 0.89466, val accuracy: 0.83789, F1 score: 0.83825
epoch: 45, loss: 5.04389
epoch: 45, train accuracy: 0.88129, val accuracy: 0.84473, F1 score: 0.84483
epoch: 46, loss: 5.04259
epoch: 46, train accuracy: 0.88129, val accuracy: 0.83105, F1 score: 0.83139
epoch: 47, loss: 5.04351
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 47, train accuracy: 0.89219, val accuracy: 0.85840, F1 score: 0.85859
epoch: 48, loss: 5.03665
epoch: 48, train accuracy: 0.89540, val accuracy: 0.85645, F1 score: 0.85693
epoch: 49, loss: 5.02779
epoch: 49, train accuracy: 0.89735, val accuracy: 0.84766, F1 score: 0.84762
epoch: 50, loss: 5.03150
epoch: 50, train accuracy: 0.89683, val accuracy: 0.85547, F1 score: 0.85574
epoch: 51, loss: 5.03145
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 51, train accuracy: 0.89531, val accuracy: 0.86426, F1 score: 0.86475
epoch: 52, loss: 5.03081
epoch: 52, train accuracy: 0.89557, val accuracy: 0.84180, F1 score: 0.84192
epoch: 53, loss: 5.02414
epoch: 53, train accuracy: 0.90213, val accuracy: 0.84766, F1 score: 0.84810
epoch: 54, loss: 5.02403
epoch: 54, train accuracy: 0.89501, val accuracy: 0.86328, F1 score: 0.86351
epoch: 55, loss: 5.02071
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 55, train accuracy: 0.87669, val accuracy: 0.83008, F1 score: 0.82994
epoch: 56, loss: 5.01735
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 56, train accuracy: 0.88459, val accuracy: 0.82715, F1 score: 0.82717
epoch: 57, loss: 5.01477
epoch: 57, train accuracy: 0.90295, val accuracy: 0.84375, F1 score: 0.84423
epoch: 58, loss: 5.01168
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 58, train accuracy: 0.89479, val accuracy: 0.84473, F1 score: 0.84497
epoch: 59, loss: 5.01796
epoch: 59, train accuracy: 0.89952, val accuracy: 0.85254, F1 score: 0.85283
epoch: 60, loss: 5.00813
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 60, train accuracy: 0.89453, val accuracy: 0.82422, F1 score: 0.82451
epoch: 61, loss: 5.00093
epoch: 61, train accuracy: 0.89462, val accuracy: 0.85352, F1 score: 0.85344
epoch: 62, loss: 4.99764
epoch: 62, train accuracy: 0.89913, val accuracy: 0.85938, F1 score: 0.85988
epoch: 63, loss: 4.99948
epoch: 63, train accuracy: 0.89444, val accuracy: 0.83789, F1 score: 0.83809
epoch: 64, loss: 5.00108
epoch: 64, train accuracy: 0.90000, val accuracy: 0.84766, F1 score: 0.84803
epoch: 65, loss: 4.99539
epoch: 65, train accuracy: 0.89470, val accuracy: 0.84473, F1 score: 0.84500
epoch: 66, loss: 4.98978
epoch: 66, train accuracy: 0.88468, val accuracy: 0.84375, F1 score: 0.84418
epoch: 67, loss: 4.99378
epoch: 67, train accuracy: 0.89097, val accuracy: 0.85352, F1 score: 0.85344
epoch: 68, loss: 4.98312
epoch: 68, train accuracy: 0.90087, val accuracy: 0.85059, F1 score: 0.85064
epoch: 69, loss: 4.97863
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 69, train accuracy: 0.87591, val accuracy: 0.82812, F1 score: 0.82825
epoch: 70, loss: 4.98217
epoch: 70, train accuracy: 0.90104, val accuracy: 0.84668, F1 score: 0.84688
epoch: 71, loss: 4.98109
epoch: 71, train accuracy: 0.90273, val accuracy: 0.86035, F1 score: 0.86070
epoch: 72, loss: 4.98396
epoch: 72, train accuracy: 0.90794, val accuracy: 0.85938, F1 score: 0.85966
epoch: 73, loss: 4.98037
epoch: 73, train accuracy: 0.90130, val accuracy: 0.86328, F1 score: 0.86351
epoch: 74, loss: 4.98144
epoch: 74, train accuracy: 0.90343, val accuracy: 0.86816, F1 score: 0.86837
epoch: 75, loss: 4.97868
epoch: 75, train accuracy: 0.89822, val accuracy: 0.86621, F1 score: 0.86642
epoch: 76, loss: 4.97192
epoch: 76, train accuracy: 0.88928, val accuracy: 0.82910, F1 score: 0.82925
epoch: 77, loss: 4.97804
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 77, train accuracy: 0.89974, val accuracy: 0.85938, F1 score: 0.85951
epoch: 78, loss: 4.98055
epoch: 78, train accuracy: 0.90365, val accuracy: 0.86816, F1 score: 0.86831
epoch: 79, loss: 4.97054
epoch: 79, train accuracy: 0.90699, val accuracy: 0.87598, F1 score: 0.87640
epoch: 80, loss: 4.96831
epoch: 80, train accuracy: 0.90833, val accuracy: 0.84863, F1 score: 0.84861
epoch: 81, loss: 4.96027
epoch: 81, train accuracy: 0.89510, val accuracy: 0.84180, F1 score: 0.84218
epoch: 82, loss: 4.96052
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 82, train accuracy: 0.90395, val accuracy: 0.87109, F1 score: 0.87128
epoch: 83, loss: 4.96571
epoch: 83, train accuracy: 0.90681, val accuracy: 0.87500, F1 score: 0.87526
epoch: 84, loss: 4.96081
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 84, train accuracy: 0.89766, val accuracy: 0.86328, F1 score: 0.86338
epoch: 85, loss: 4.96329
epoch: 85, train accuracy: 0.90187, val accuracy: 0.85645, F1 score: 0.85657
epoch: 86, loss: 4.96017
epoch: 86, train accuracy: 0.89427, val accuracy: 0.83984, F1 score: 0.83993
epoch: 87, loss: 4.96603
epoch: 87, train accuracy: 0.89314, val accuracy: 0.83984, F1 score: 0.83989
epoch: 88, loss: 4.95759
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 88, train accuracy: 0.90143, val accuracy: 0.86035, F1 score: 0.86054
epoch: 89, loss: 4.95367
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 89, train accuracy: 0.90148, val accuracy: 0.85352, F1 score: 0.85373
epoch: 90, loss: 4.95339
epoch: 90, train accuracy: 0.90590, val accuracy: 0.84570, F1 score: 0.84605
epoch: 91, loss: 4.94733
/home/aksavadogo/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.
Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(
epoch: 91, train accuracy: 0.91202, val accuracy: 0.86035, F1 score: 0.86062
epoch: 92, loss: 4.94948
epoch: 92, train accuracy: 0.90955, val accuracy: 0.87891, F1 score: 0.87918
epoch: 93, loss: 4.94781
epoch: 93, train accuracy: 0.90694, val accuracy: 0.85742, F1 score: 0.85769
epoch: 94, loss: 4.95403
epoch: 94, train accuracy: 0.89527, val accuracy: 0.84277, F1 score: 0.84271
epoch: 95, loss: 4.94361
epoch: 95, train accuracy: 0.91007, val accuracy: 0.87988, F1 score: 0.88024
epoch: 96, loss: 4.94272
epoch: 96, train accuracy: 0.90751, val accuracy: 0.87598, F1 score: 0.87611
epoch: 97, loss: 4.94445
epoch: 97, train accuracy: 0.90872, val accuracy: 0.85547, F1 score: 0.85551
epoch: 98, loss: 4.94161
epoch: 98, train accuracy: 0.90690, val accuracy: 0.87207, F1 score: 0.87227
epoch: 99, loss: 4.94058
epoch: 99, train accuracy: 0.91181, val accuracy: 0.87109, F1 score: 0.87128
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for post_run_cell), with arguments args (<ExecutionResult object at 761c2364b410, execution_count=15 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 761c20009990, raw_cell="# Note: The model and training settings do not fol.." store_history=True silent=False shell_futures=True cell_id=43b47201-d118-42aa-b4e4-410fd43a23e4> result=None>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 761c9948d310, raw_cell="_jupyterlab_variableinspector_dict_list()" store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for post_run_cell), with arguments args (<ExecutionResult object at 761be6186490, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 761c9948d310, raw_cell="_jupyterlab_variableinspector_dict_list()" store_history=False silent=False shell_futures=True cell_id=None> result='[{"varName": "avg_loss", "varType": "float", "varSize": "24", "varShape": "", "varContent": "4.940578752093845", "isMatrix": false, "isWidget": false}, {"varName": "backbone", "varType": "Sequential", "varSize": "56", "varShape": "", "varContent": "Sequential(\\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine ...", "isMatrix": false, "isWidget": false}, {"varName": "batch", "varType": "list", "varSize": "120", "varShape": "2", "varContent": "[[tensor([[[[-0.6965, -0.7308, -0.7308,  ..., -1.8097, -1.8097, -1.8097],\\n          [-0.7308, -0.6965, -0.7308,  ..., -1.8097, -1.8097, -1.8097],\\n     ...", "isMatrix": true, "isWidget": false}, {"varName": "classifier", "varType": "LogisticRegression", "varSize": "56", "varShape": "", "varContent": "LogisticRegression(max_iter=1000)", "isMatrix": false, "isWidget": false}, {"varName": "criterion", "varType": "NTXentLoss", "varSize": "56", "varShape": "", "varContent": "NTXentLoss(\\n  (cross_entropy): CrossEntropyLoss()\\n)", "isMatrix": false, "isWidget": false}, {"varName": "device", "varType": "str", "varSize": "53", "varShape": "", "varContent": "cuda", "isMatrix": false, "isWidget": false}, {"varName": "epoch", "varType": "int", "varSize": "28", "varShape": "", "varContent": "99", "isMatrix": false, "isWidget": false}, {"varName": "f1", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.8712793989547039", "isMatrix": false, "isWidget": false}, {"varName": "features", "varType": "Tensor", "varSize": "524288", "varShape": "256 x 512", "varContent": "tensor([[0.0000, 0.0000, 1.4114,  ..., 0.0000, 0.0000, 0.5158],\\n        [0.0000, 0.1700, 1.2028,  ..., 0.0000, 0.0000, 0.0000],\\n        [0.0000, 0.000 ...", "isMatrix": true, "isWidget": false}, {"varName": "labels", "varType": "Tensor", "varSize": "2048", "varShape": "256", "varContent": "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...", "isMatrix": true, "isWidget": false}, {"varName": "loss", "varType": "Tensor", "varSize": "4", "varShape": "", "varContent": "tensor(4.9247, device=\'cuda:0\', grad_fn=<NllLossBackward0>)", "isMatrix": true, "isWidget": false}, {"varName": "model", "varType": "SimCLR", "varSize": "56", "varShape": "", "varContent": "SimCLR(\\n  (backbone): Sequential(\\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n    (1): BatchNorm2d(64, eps=1 ...", "isMatrix": false, "isWidget": false}, {"varName": "optimizer", "varType": "SGD", "varSize": "56", "varShape": "", "varContent": "SGD (\\nParameter Group 0\\n    dampening: 0\\n    differentiable: False\\n    foreach: None\\n    fused: None\\n    lr: 0.06\\n    maximize: False\\n    momentum: 0\\n ...", "isMatrix": false, "isWidget": false}, {"varName": "resnet", "varType": "ResNet", "varSize": "56", "varShape": "", "varContent": "ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affi ...", "isMatrix": false, "isWidget": false}, {"varName": "total_loss", "varType": "float", "varSize": "24", "varShape": "", "varContent": "444.65208768844604", "isMatrix": false, "isWidget": false}, {"varName": "train_accuracy", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.9118055555555555", "isMatrix": false, "isWidget": false}, {"varName": "train_dataset", "varType": "ImageFolder", "varSize": "56", "varShape": "", "varContent": "Dataset ImageFolder\\n    Number of datapoints: 23137\\n    Root location: hscurvedataset/train\\n    StandardTransform\\nTransform: <lightly.transforms.simcl ...", "isMatrix": false, "isWidget": false}, {"varName": "train_features", "varType": "ndarray", "varSize": "47185920", "varShape": "23040 x 512", "varContent": "array([[0.6343852 , 0.        , 0.29635867, ..., 0.        , 1.0908078 ,\\n        0.50081193],\\n       [1.2845516 , 1.7191604 , 0.        , ..., 2.12351 ...", "isMatrix": true, "isWidget": false}, {"varName": "train_labels", "varType": "ndarray", "varSize": "184320", "varShape": "23040", "varContent": "array([0, 0, 0, ..., 0, 1, 1])", "isMatrix": true, "isWidget": false}, {"varName": "train_predictions", "varType": "ndarray", "varSize": "184320", "varShape": "23040", "varContent": "array([0, 0, 0, ..., 0, 1, 1])", "isMatrix": true, "isWidget": false}, {"varName": "val_accuracy", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.87109375", "isMatrix": false, "isWidget": false}, {"varName": "val_dataset", "varType": "ImageFolder", "varSize": "56", "varShape": "", "varContent": "Dataset ImageFolder\\n    Number of datapoints: 1160\\n    Root location: hscurvedataset/val\\n    StandardTransform\\nTransform: <lightly.transforms.simclr_t ...", "isMatrix": false, "isWidget": false}, {"varName": "val_features", "varType": "ndarray", "varSize": "2097152", "varShape": "1024 x 512", "varContent": "array([[3.3676019 , 0.1315718 , 0.662981  , ..., 0.4439404 , 0.        ,\\n        0.65889525],\\n       [0.        , 0.        , 1.286943  , ..., 0.      ...", "isMatrix": true, "isWidget": false}, {"varName": "val_labels", "varType": "ndarray", "varSize": "8192", "varShape": "1024", "varContent": "array([0, 0, 0, ..., 1, 1, 1])", "isMatrix": true, "isWidget": false}, {"varName": "val_predictions", "varType": "ndarray", "varSize": "8192", "varShape": "1024", "varContent": "array([1, 0, 0, ..., 1, 1, 0])", "isMatrix": true, "isWidget": false}, {"varName": "x0", "varType": "Tensor", "varSize": "3145728", "varShape": "256 x 3 x 32 x 32", "varContent": "tensor([[[[-2.1008, -2.1008, -2.1008,  ..., -1.7925, -1.9295, -2.1008],\\n          [-2.1008, -2.1008, -2.1008,  ..., -2.0323, -2.0837, -2.1008],\\n       ...", "isMatrix": false, "isWidget": false}, {"varName": "x1", "varType": "Tensor", "varSize": "3145728", "varShape": "256 x 3 x 32 x 32", "varContent": "tensor([[[[-0.7137, -0.7137, -0.7137,  ..., -0.0629,  0.0056, -0.0629],\\n          [-0.7137, -0.7137, -0.7137,  ..., -0.1143, -0.0629, -0.3198],\\n       ...", "isMatrix": false, "isWidget": false}, {"varName": "z0", "varType": "Tensor", "varSize": "131072", "varShape": "256 x 128", "varContent": "tensor([[ 0.6124, -0.1804, -0.3864,  ..., -0.2597, -0.5280, -0.0222],\\n        [-0.2167, -1.0587,  2.3276,  ...,  0.1956,  1.0645, -0.1949],\\n        [- ...", "isMatrix": true, "isWidget": false}, {"varName": "z1", "varType": "Tensor", "varSize": "131072", "varShape": "256 x 128", "varContent": "tensor([[ 0.5190, -0.0226, -0.5226,  ..., -0.1092, -0.4920,  0.1631],\\n        [-0.1039, -1.0191,  2.6630,  ...,  0.2058,  1.2353, -0.3698],\\n        [- ...", "isMatrix": true, "isWidget": false}]'>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 761c232b9d90, raw_cell="
import json
import getpass
import hashlib
def im.." store_history=True silent=False shell_futures=True cell_id=None>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for post_run_cell), with arguments args (<ExecutionResult object at 761be6185010, execution_count=16 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 761c232b9d90, raw_cell="
import json
import getpass
import hashlib
def im.." store_history=True silent=False shell_futures=True cell_id=None> result='{"dataframes": [], "user": "aksavadogo"}'>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 761c00033f50, raw_cell="_jupyterlab_variableinspector_dict_list()" store_history=False silent=False shell_futures=True cell_id=None>,),kwargs {}:
Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for post_run_cell), with arguments args (<ExecutionResult object at 761c98956e90, execution_count=None error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 761c00033f50, raw_cell="_jupyterlab_variableinspector_dict_list()" store_history=False silent=False shell_futures=True cell_id=None> result='[{"varName": "avg_loss", "varType": "float", "varSize": "24", "varShape": "", "varContent": "4.940578752093845", "isMatrix": false, "isWidget": false}, {"varName": "backbone", "varType": "Sequential", "varSize": "56", "varShape": "", "varContent": "Sequential(\\n  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine ...", "isMatrix": false, "isWidget": false}, {"varName": "batch", "varType": "list", "varSize": "120", "varShape": "2", "varContent": "[[tensor([[[[-0.6965, -0.7308, -0.7308,  ..., -1.8097, -1.8097, -1.8097],\\n          [-0.7308, -0.6965, -0.7308,  ..., -1.8097, -1.8097, -1.8097],\\n     ...", "isMatrix": true, "isWidget": false}, {"varName": "classifier", "varType": "LogisticRegression", "varSize": "56", "varShape": "", "varContent": "LogisticRegression(max_iter=1000)", "isMatrix": false, "isWidget": false}, {"varName": "criterion", "varType": "NTXentLoss", "varSize": "56", "varShape": "", "varContent": "NTXentLoss(\\n  (cross_entropy): CrossEntropyLoss()\\n)", "isMatrix": false, "isWidget": false}, {"varName": "device", "varType": "str", "varSize": "53", "varShape": "", "varContent": "cuda", "isMatrix": false, "isWidget": false}, {"varName": "epoch", "varType": "int", "varSize": "28", "varShape": "", "varContent": "99", "isMatrix": false, "isWidget": false}, {"varName": "f1", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.8712793989547039", "isMatrix": false, "isWidget": false}, {"varName": "features", "varType": "Tensor", "varSize": "524288", "varShape": "256 x 512", "varContent": "tensor([[0.0000, 0.0000, 1.4114,  ..., 0.0000, 0.0000, 0.5158],\\n        [0.0000, 0.1700, 1.2028,  ..., 0.0000, 0.0000, 0.0000],\\n        [0.0000, 0.000 ...", "isMatrix": true, "isWidget": false}, {"varName": "labels", "varType": "Tensor", "varSize": "2048", "varShape": "256", "varContent": "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...", "isMatrix": true, "isWidget": false}, {"varName": "loss", "varType": "Tensor", "varSize": "4", "varShape": "", "varContent": "tensor(4.9247, device=\'cuda:0\', grad_fn=<NllLossBackward0>)", "isMatrix": true, "isWidget": false}, {"varName": "model", "varType": "SimCLR", "varSize": "56", "varShape": "", "varContent": "SimCLR(\\n  (backbone): Sequential(\\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n    (1): BatchNorm2d(64, eps=1 ...", "isMatrix": false, "isWidget": false}, {"varName": "optimizer", "varType": "SGD", "varSize": "56", "varShape": "", "varContent": "SGD (\\nParameter Group 0\\n    dampening: 0\\n    differentiable: False\\n    foreach: None\\n    fused: None\\n    lr: 0.06\\n    maximize: False\\n    momentum: 0\\n ...", "isMatrix": false, "isWidget": false}, {"varName": "resnet", "varType": "ResNet", "varSize": "56", "varShape": "", "varContent": "ResNet(\\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affi ...", "isMatrix": false, "isWidget": false}, {"varName": "total_loss", "varType": "float", "varSize": "24", "varShape": "", "varContent": "444.65208768844604", "isMatrix": false, "isWidget": false}, {"varName": "train_accuracy", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.9118055555555555", "isMatrix": false, "isWidget": false}, {"varName": "train_dataset", "varType": "ImageFolder", "varSize": "56", "varShape": "", "varContent": "Dataset ImageFolder\\n    Number of datapoints: 23137\\n    Root location: hscurvedataset/train\\n    StandardTransform\\nTransform: <lightly.transforms.simcl ...", "isMatrix": false, "isWidget": false}, {"varName": "train_features", "varType": "ndarray", "varSize": "47185920", "varShape": "23040 x 512", "varContent": "array([[0.6343852 , 0.        , 0.29635867, ..., 0.        , 1.0908078 ,\\n        0.50081193],\\n       [1.2845516 , 1.7191604 , 0.        , ..., 2.12351 ...", "isMatrix": true, "isWidget": false}, {"varName": "train_labels", "varType": "ndarray", "varSize": "184320", "varShape": "23040", "varContent": "array([0, 0, 0, ..., 0, 1, 1])", "isMatrix": true, "isWidget": false}, {"varName": "train_predictions", "varType": "ndarray", "varSize": "184320", "varShape": "23040", "varContent": "array([0, 0, 0, ..., 0, 1, 1])", "isMatrix": true, "isWidget": false}, {"varName": "val_accuracy", "varType": "float64", "varSize": "32", "varShape": "", "varContent": "0.87109375", "isMatrix": false, "isWidget": false}, {"varName": "val_dataset", "varType": "ImageFolder", "varSize": "56", "varShape": "", "varContent": "Dataset ImageFolder\\n    Number of datapoints: 1160\\n    Root location: hscurvedataset/val\\n    StandardTransform\\nTransform: <lightly.transforms.simclr_t ...", "isMatrix": false, "isWidget": false}, {"varName": "val_features", "varType": "ndarray", "varSize": "2097152", "varShape": "1024 x 512", "varContent": "array([[3.3676019 , 0.1315718 , 0.662981  , ..., 0.4439404 , 0.        ,\\n        0.65889525],\\n       [0.        , 0.        , 1.286943  , ..., 0.      ...", "isMatrix": true, "isWidget": false}, {"varName": "val_labels", "varType": "ndarray", "varSize": "8192", "varShape": "1024", "varContent": "array([0, 0, 0, ..., 1, 1, 1])", "isMatrix": true, "isWidget": false}, {"varName": "val_predictions", "varType": "ndarray", "varSize": "8192", "varShape": "1024", "varContent": "array([1, 0, 0, ..., 1, 1, 0])", "isMatrix": true, "isWidget": false}, {"varName": "x0", "varType": "Tensor", "varSize": "3145728", "varShape": "256 x 3 x 32 x 32", "varContent": "tensor([[[[-2.1008, -2.1008, -2.1008,  ..., -1.7925, -1.9295, -2.1008],\\n          [-2.1008, -2.1008, -2.1008,  ..., -2.0323, -2.0837, -2.1008],\\n       ...", "isMatrix": false, "isWidget": false}, {"varName": "x1", "varType": "Tensor", "varSize": "3145728", "varShape": "256 x 3 x 32 x 32", "varContent": "tensor([[[[-0.7137, -0.7137, -0.7137,  ..., -0.0629,  0.0056, -0.0629],\\n          [-0.7137, -0.7137, -0.7137,  ..., -0.1143, -0.0629, -0.3198],\\n       ...", "isMatrix": false, "isWidget": false}, {"varName": "z0", "varType": "Tensor", "varSize": "131072", "varShape": "256 x 128", "varContent": "tensor([[ 0.6124, -0.1804, -0.3864,  ..., -0.2597, -0.5280, -0.0222],\\n        [-0.2167, -1.0587,  2.3276,  ...,  0.1956,  1.0645, -0.1949],\\n        [- ...", "isMatrix": true, "isWidget": false}, {"varName": "z1", "varType": "Tensor", "varSize": "131072", "varShape": "256 x 128", "varContent": "tensor([[ 0.5190, -0.0226, -0.5226,  ..., -0.1092, -0.4920,  0.1631],\\n        [-0.1039, -1.0191,  2.6630,  ...,  0.2058,  1.2353, -0.3698],\\n        [- ...", "isMatrix": true, "isWidget": false}]'>,),kwargs {}:
Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x761c23b15b90>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 761c23402310, raw_cell="import wandb
wandb.login()
run = wandb.init(
   .." store_history=True silent=False shell_futures=True cell_id=a78334a4-6b77-4df9-8eee-62053fe38f07>,),kwargs {}:
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.